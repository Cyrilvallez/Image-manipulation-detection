---
name : Benchmark_dev_machine
date generated: Monday 21/03/2022
GPU(s): dev machine (1 rtx)
CPUs: dev machine (unknown at this point)
dataset used: BSDS500, with attacks on disk
thresholds: np.linspace(0, 0.4, 10)
algorithms:  [
    hashing.ClassicalAlgorithm('Ahash', hash_size=8, batch_size=256),
    hashing.ClassicalAlgorithm('Phash', hash_size=8, batch_size=256),
    hashing.ClassicalAlgorithm('Dhash', hash_size=8, batch_size=256),
    hashing.ClassicalAlgorithm('Whash', hash_size=8, batch_size=256),
    hashing.ClassicalAlgorithm('Crop resistant hash', hash_size=8, batch_size=256),
    hashing.NeuralAlgorithm('Inception v3', raw_features=True, batch_size=256,
                            device='cuda', distance='cosine'),
    hashing.NeuralAlgorithm('Inception v3', raw_features=True, batch_size=256,
                            device='cuda', distance='Jensen-Shannon'),
    hashing.NeuralAlgorithm('SimCLR v1 ResNet50 2x', raw_features=True, batch_size=256,
                            device='cuda', distance='cosine'),
    hashing.NeuralAlgorithm('SimCLR v1 ResNet50 2x', raw_features=True, batch_size=256,
                            device='cuda', distance='Jensen-Shannon')
    ]
general batch size: 256

---
purpose: |
Benchmark the new hashing pipeline and get an idea of the computational cost of neural hashing now that it is optimized in batches and run on GPU efficiently. 
Also get an idea of how well the Jensen-Shannon distance is performing compared to other methods and cosine distance.
This is the same experiment as First_benchmark but runned on the dev machine instead of the cluster to get a consistent running time since there are
issues in the cluster.